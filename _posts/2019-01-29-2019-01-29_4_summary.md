---
layout: post
title: 2019/01/29 33 Updates (1 - 10)
---
#### [1. Artificial intelligence and machine learning for human reproduction and embryology presented at ASRM and ESHRE 2018.](https://doi.org/10.1007/s10815-019-01408-x){: .btn}
**Authors:** *Curchoe Carol Lynn, Bormann Charles L*

**Journal:** *Journal of assisted reproduction and genetics*

*abstract:* Sixteen artificial intelligence (AI) and machine learning (ML) approaches were reported at the 2018 annual congresses of the American Society for Reproductive Biology (9) and European Society for Human Reproduction and Embryology (7). Nearly every aspect of patient care was investigated, including sperm morphology, sperm identification, identification of empty or oocyte containing follicles, predicting embryo cell stages, predicting blastocyst formation from oocytes, assessing human blastocyst quality, predicting live birth from blastocysts, improving embryo selection, and for developing optimal IVF stimulation protocols. This represents a substantial increase in reports over 2017, where just one abstract each was reported at ASRM (AI) and ESHRE (ML). Our analysis reveals wide variability in how AI and ML methods are described (from not at all or very generic to fully describing the architectural framework) and large variability on accepted dataset sizes (from just 3 patients with 16 follicles in the smallest dataset to 661,060 images of 11,898 human embryos in one of the largest). AI and ML are clearly burgeoning methodologies in human reproduction and embryology and would benefit from early application of reporting standards.

**Keywords:** **'ASHRE', 'ASRM', 'Artificial intelligence', 'Embryology', 'Human reproduction', 'Machine learning'**

**Publication Date:** *2019-Jan-28*

#### [2. Assessment of advanced random forest and decision tree algorithms for modeling rainfall-induced landslide susceptibility in the Izu-Oshima Volcanic Island, Japan.](https://linkinghub.elsevier.com/retrieve/pii/S0048-9697(19)30305-5){: .btn}
**Authors:** *Dou Jie, Yunus Ali P, Tien Bui Dieu, Merghadi Abdelaziz, Sahana Mehebub, Zhu Zhongfan, Chen Chi-Wen, Khosravi Khabat, Yang Yong, Pham Binh Thai*

**Journal:** *The Science of the total environment*

*abstract:* Landslides represent a part of the cascade of geological hazards in a wide range of geo-environments. In this study, we aim to investigate and compare the performance of two state-of-the-art machine learning models, i.e., decision tree (DT) and random forest (RF) approaches to model the massive rainfall-triggered landslide occurrences in the Izu-Oshima Volcanic Island, Japan at a regional scale. At first, a landslide inventory map is prepared consisting of 44 landslide polygons (10,444 pixels) from aerial photo-interpretation and field surveys. To estimate the robustness of the models, we randomly adapted two different samples (S1 and S2), comprising of both positive and negative cells (70% of total landslides - 7293 pixels) for training and remaining (30%-3151 pixels) for validation. Twelve causative factors including altitude, slope angle, slope aspect, plan curvature, total curvature, compound topographic index, stream power index, distance to drainage network, drainage density, distance to geological boundaries, lithology and cumulative rainfall were selected as predictors to implement the landslide susceptibility model. The area under the receiver operating characteristics (ROC) curves (AUC) and other statistical signifiers were used to verify the model accuracies. The result shows that the DT and RF models achieved remarkable predictive performance (AUC > 0.9), producing near accurate susceptibility maps. The overall efficiency of RF (AUC = 0.956) is found significantly higher than the DT (AUC = 0.928) results. Additionally, we noticed that the performance of RF for modeling landslide susceptibility is very robust even though the training and validation samples are altered. Considering the performances, we suggest that both RF and DT models can be used in other similar non-eruption-related landslide studies in the tephra-deposited rich volcanoes, as they are capable of rapidly generating accurate and stable LSM maps for risk mitigation, management practices, and decision-making. Moreover, the RF-based model is promising and enough to be recommended as a method to map regional landslide susceptibility.

**Keywords:** **'Decision tree', 'Izu-Oshima Volcano Island', 'Machine learning', 'Rainfall-induced landslide', 'Random forest', 'Susceptibility'**

**Publication Date:** *2019-Jan-21*

#### [3. Image-based velocity estimation of rock using Convolutional Neural Networks.](https://linkinghub.elsevier.com/retrieve/pii/S0893-6080(18)30337-X){: .btn}
**Authors:** *Karimpouli Sadegh, Tahmasebi Pejman*

**Journal:** *Neural networks : the official journal of the International Neural Network Society*

*abstract:* Digital images of rock samples have been using extensively in Digital Rock Physics (DRP) to evaluate physical parameters of rock such as permeability, P- and S-wave velocities and formation factor. The parameters are numerically computed by simulation of the corresponding physical processes through segmented image of rock, which provide a direct and accurate evaluation of rock properties. However, recent advances in machine learning and Convolutional Neural Networks (CNN) allow using images as input. Such networks, however, require a considerable number of images as input. In this paper, CNNs are used to estimate the P- and S-wave velocities from images of rock medium. To deal with lack of input data, a hybrid pattern- and pixel-based simulation (HYPPS) is used as an efficient data augmentation method to increase the training data set. For each input image, 10 stochastic realizations are produced. Compare to the case wherein the stochastic models are not used, the new results from the enhanced network indicate a sharp improvement in the estimations such that R

**Keywords:** **'Artificial intelligence', 'Digital Rock Physics (DRP)', 'HYPPS', 'P- and S-wave velocities'**

**Publication Date:** *2019-Jan-09*

#### [4. Implementation and relevance of FAIR data principles in biopharmaceutical R&D.](https://linkinghub.elsevier.com/retrieve/pii/S1359-6446(18)30303-9){: .btn}
**Authors:** *Wise John, de Barron Alexandra Grebe, Splendiani Andrea, Balali-Mood Beeta, Vasant Drashtti, Little Eric, Mellino Gaspare, Harrow Ian, Smith Ian, Taubert Jan, van Bochove Kees, Romacker Martin, Walgemoed Peter, Jimenez Rafael C, Winnerberg Rainer, Plasterer Tom, Gupta Vibhor, Hedley Victoria*

**Journal:** *Drug discovery today*

*abstract:* Biopharmaceutical industry R&D, and indeed other life sciences R&D such as biomedical, environmental, agricultural and food production, is becoming increasingly data-driven and can significantly improve its efficiency and effectiveness by implementing the FAIR (findable, accessible, interoperable, reusable) guiding principles for scientific data management and stewardship. By so doing, the plethora of new and powerful analytical tools such as artificial intelligence and machine learning will be able, automatically and at scale, to access the data from which they learn, and on which they thrive. FAIR is a fundamental enabler for digital transformation.



**Publication Date:** *2019-Jan-25*

#### [5. Intracortical smoothing of small-voxel fMRI data can provide increased detection power without spatial resolution losses compared to conventional large-voxel fMRI data.](https://linkinghub.elsevier.com/retrieve/pii/S1053-8119(19)30048-5){: .btn}
**Authors:** *Blazejewska Anna I, Fischl Bruce, Wald Lawrence L, Polimeni Jonathan R*

**Journal:** *NeuroImage*

*abstract:* Continued improvement in MRI acquisition technology has made functional MRI (fMRI) with small isotropic voxel sizes down to 1 mm and below more commonly available. Although many conventional fMRI studies seek to investigate regional patterns of cortical activation for which conventional voxel sizes of 3 mm and larger provide sufficient spatial resolution, smaller voxels can help avoid contamination from adjacent white matter (WM) and cerebrospinal fluid (CSF), and thereby increase the specificity of fMRI to signal changes within the gray matter. Unfortunately, temporal signal-to-noise ratio (tSNR), a metric of fMRI sensitivity, is reduced in high-resolution acquisitions, which offsets the benefits of small voxels. Here we introduce a framework that combines small, isotropic fMRI voxels acquired at 7 T field strength with a novel anatomically-informed, surface mesh-navigated spatial smoothing that can provide both higher detection power and higher resolution than conventional voxel sizes. Our smoothing approach uses a family of intracortical surface meshes and allows for kernels of various shapes and sizes, including curved 3D kernels that adapt to and track the cortical folding pattern. Our goal is to restrict smoothing to the cortical gray matter ribbon and avoid noise contamination from CSF and signal dilution from WM via partial volume effects. We found that the intracortical kernel that maximizes tSNR does not maximize percent signal change (ΔS/S), and therefore the kernel configuration that optimizes detection power cannot be determined from tSNR considerations alone. However, several kernel configurations provided a favorable balance between boosting tSNR and ΔS/S, and allowed a 1.1-mm isotropic fMRI acquisition to have higher performance after smoothing (in terms of both detection power and spatial resolution) compared to an unsmoothed 3.0-mm isotropic fMRI acquisition. Overall, the results of this study support the strategy of acquiring voxels smaller than the cortical thickness, even for studies not requiring high spatial resolution, and smoothing them down within the cortical ribbon with a kernel of an appropriate shape to achieve the best performance-thus decoupling the choice of fMRI voxel size from the spatial resolution requirements of the particular study. The improvement of this new intracortical smoothing approach over conventional surface-based smoothing is expected to be modest for conventional resolutions, however the improvement is expected to increase with higher resolutions. This framework can also be applied to anatomically-informed intracortical smoothing of higher-resolution data (e.g. along columns and layers) in studies with prior information about the spatial structure of activation.

**Keywords:** **'Columnar fMRI', 'Cortical depth analysis', 'High-resolution fMRI', 'Laminar fMRI', 'Physiological noise', 'Spatial smoothing', 'Surface-based analysis', 'fMRI analysis'**

**Publication Date:** *2019-Jan-25*

#### [6. A Deep Learning Algorithm to Quantify Neuroretinal Rim Loss from Optic Disc Photographs.](https://linkinghub.elsevier.com/retrieve/pii/S0002-9394(19)30024-8){: .btn}
**Authors:** *Thompson Atalie C, Jammal Alessandro A, Medeiros Felipe A*

**Journal:** *American journal of ophthalmology*

*abstract:* To train a deep learning (DL) algorithm that quantifies glaucomatous neuroretinal damage on fundus photographs using the minimum rim width relative to Bruch's membrane opening (BMO-MRW) from spectral domain-optical coherence tomography (SDOCT).



**Publication Date:** *2019-Jan-25*

#### [7. A new method for detecting autocorrelation of evolutionary rates in large phylogenies.](https://academic.oup.com/mbe/article-lookup/doi/10.1093/molbev/msz014){: .btn}
**Authors:** *Tao Qiqing, Tamura Koichiro, Battistuzzi Fabia, Kumar Sudhir*

**Journal:** *Molecular biology and evolution*

*abstract:* New species arise from pre-existing species and inherit similar genomes and environments. This predicts greater similarity of the tempo of molecular evolution between direct ancestors and descendants, resulting in autocorrelation of evolutionary rates in the tree of life. Surprisingly, molecular sequence data have not confirmed this expectation, possibly because available methods lack the power to detect autocorrelated rates. Here we present a machine learning method, CorrTest, to detect the presence of rate autocorrelation in large phylogenies. CorrTest is computationally efficient and performs better than the available state-of-the-art methods. Application of CorrTest reveals extensive rate autocorrelation in DNA and amino acid sequence evolution of mammals, birds, insects, metazoans, plants, fungi, parasitic protozoans, and prokaryotes. Therefore, rate autocorrelation is a common phenomenon throughout the tree of life. These findings suggest concordance between molecular and non-molecular evolutionary patterns, and they will foster unbiased and precise dating of the tree of life.



**Publication Date:** *2019-Jan-23*

#### [8. NanoPipe - a web server for nanopore MinION sequencing data analysis.](https://academic.oup.com/gigascience/article-lookup/doi/10.1093/gigascience/giy169){: .btn}
**Authors:** *Shabardina Victoria, Kischka Tabea, Manske Felix, Grundmann Norbert, Frith Martin C, Suzuki Yutaka, Makalowski Wojciech*

**Journal:** *GigaScience*

*abstract:* The fast-moving progress of the third generation long read sequencing technologies will soon bring the biological and medical sciences to a new era of research. Altogether the technique and experimental procedures are becoming more straightforward and available to biologists from diverse fields, even without any profound experience in DNA sequencing. Thus, the introduction of the MinIONTM device by Oxford Nanopore Technologies promises to "bring sequencing technology to the masses" and also allows quick and operative analysis in field studies. However, the convenience of this sequencing technology dramatically contrasts with the available analysis tools, which may significantly reduce enthusiasm of a "regular" user. To really bring the sequencing technology to every biologist, we need a set of user-friendly tools that can perform a powerful analysis in an automatic manner.



**Publication Date:** *2019-Jan-24*

#### [9. Overview of the BioCreative VI Precision Medicine Track: mining protein interactions and mutations for precision medicine.](https://academic.oup.com/database/article-lookup/doi/10.1093/database/bay147){: .btn}
**Authors:** *Islamaj Dogan Rezarta, Kim Sun, Chatr-Aryamontri Andrew, Wei Chih-Hsuan, Comeau Donald C, Antunes Rui, Matos Sérgio, Chen Qingyu, Elangovan Aparna, Panyam Nagesh C, Verspoor Karin, Liu Hongfang, Wang Yanshan, Liu Zhuang, Altinel Berna, Hüsünbeyi Zehra Melce, Özgür Arzucan, Fergadis Aris, Wang Chen-Kai, Dai Hong-Jie, Tran Tung, Kavuluru Ramakanth, Luo Ling, Steppi Albert, Zhang Jinfeng, Qu Jinchan, Lu Zhiyong*

**Journal:** *Database : the journal of biological databases and curation*

*abstract:* The Precision Medicine Initiative is a multicenter effort aiming at formulating personalized treatments leveraging on individual patient data (clinical, genome sequence and functional genomic data) together with the information in large knowledge bases (KBs) that integrate genome annotation, disease association studies, electronic health records and other data types. The biomedical literature provides a rich foundation for populating these KBs, reporting genetic and molecular interactions that provide the scaffold for the cellular regulatory systems and detailing the influence of genetic variants in these interactions. The goal of BioCreative VI Precision Medicine Track was to extract this particular type of information and was organized in two tasks: (i) document triage task, focused on identifying scientific literature containing experimentally verified protein-protein interactions (PPIs) affected by genetic mutations and (ii) relation extraction task, focused on extracting the affected interactions (protein pairs). To assist system developers and task participants, a large-scale corpus of PubMed documents was manually annotated for this task. Ten teams worldwide contributed 22 distinct text-mining models for the document triage task, and six teams worldwide contributed 14 different text-mining systems for the relation extraction task. When comparing the text-mining system predictions with human annotations, for the triage task, the best F-score was 69.06%, the best precision was 62.89%, the best recall was 98.0% and the best average precision was 72.5%. For the relation extraction task, when taking homologous genes into account, the best F-score was 37.73%, the best precision was 46.5% and the best recall was 54.1%. Submitted systems explored a wide range of methods, from traditional rule-based, statistical and machine learning systems to state-of-the-art deep learning methods. Given the level of participation and the individual team results we find the precision medicine track to be successful in engaging the text-mining research community. In the meantime, the track produced a manually annotated corpus of 5509 PubMed documents developed by BioGRID curators and relevant for precision medicine. The data set is freely available to the community, and the specific interactions have been integrated into the BioGRID data set. In addition, this challenge provided the first results of automatically identifying PubMed articles that describe PPI affected by mutations, as well as extracting the affected relations from those articles. Still, much progress is needed for computer-assisted precision medicine text mining to become mainstream. Future work should focus on addressing the remaining technical challenges and incorporating the practical benefits of text-mining tools into real-world precision medicine information-related curation.



**Publication Date:** *2019-01-01*

#### [10. Machine learning algorithms estimating prognosis and guiding therapy in adult congenital heart disease: data from a single tertiary centre including 10 019 patients.](https://academic.oup.com/eurheartj/article-lookup/doi/10.1093/eurheartj/ehy915){: .btn}
**Authors:** *Diller Gerhard-Paul, Kempny Aleksander, Babu-Narayan Sonya V, Henrichs Marthe, Brida Margarita, Uebing Anselm, Lammers Astrid E, Baumgartner Helmut, Li Wei, Wort Stephen J, Dimopoulos Konstantinos, Gatzoulis Michael A*

**Journal:** *European heart journal*

*abstract:* To assess the utility of machine learning algorithms on estimating prognosis and guiding therapy in a large cohort of patients with adult congenital heart disease (ACHD) or pulmonary hypertension at a single, tertiary centre.



**Publication Date:** *2019-Jan-26*

