---
layout: post
title: 2019/02/01 41 Updates (1 - 10)
---
#### [1. Potential EEG biomarkers of sedation doses in intensive care patients unveiled by using a machine learning approach.](https://doi.org/10.1088/1741-2552/ab039f){: .btn}
**Authors:** *Sanz-Garcia Ancor, Perez-Romero Miriam, Pastor Jesus, Sola Rafael G, Vega-Zelaya Lorena, Vega Gema, Monasterio Fernando, Torrecilla Carmen, Pulido Paloma, Ortega Guillermo J*

**Journal:** *Journal of neural engineering*

*abstract:* Sedation of neurocritically ill patients is one of the most challenging situation in ICUs. Quantitative knowledge on the sedation effect on brain activity in that complex scenario could help to uncover new markers for sedation assessment. Hence, we aim to evaluate the existence of changes of diverse EEG-derived measures in deeply-sedated (RASS -Richmond Agitation-Sedation Scale- -4 and -5) neurocritically ill patients, and also whether sedation doses are related with those eventual changes. &#13; Approach: We performed an observational prospective cohort study in the Intensive Care Unit of the Hospital de la Princesa. Twenty-six adult patients suffered from Traumatic Brain Injury and Subarachnoid Hemorrhage were included in the present study. Long-term continuous electroencephalographic (EEG) recordings (2141h) and hourly annotated information were used to determine the relationship between intravenous sedation infusion doses and network and spectral EEG measures. To do that, two different strategies were followed: assessment of the statistical dependence between both variables using the Spearman correlation rank and by performing an automatic classification method based on a machine learning algorithm.&#13; Main results: More than 60% of patients presented a correlation greater than 0.5 in at least one of the calculated EEG measures with the sedation dose. The automatic classification method presented an accuracy of 84.3% in discriminating between different sedation doses. In both cases the nodes' degree was the most relevant measurement.&#13; Significance: The results presented here provide evidences of brain activity changes during deep sedation linked to sedation doses. Particularly, the capability of network EEG-derived measures in discriminating between different sedation doses could be the framework for the development of accurate methods for sedation levels assessment.

**Keywords:** **'EEG', 'ICU', 'brain networks', 'machine learning', 'sedation'**

**Publication Date:** *2019-Jan-31*

#### [2. Three-dimensional radiotherapy dose prediction on head and neck cancer patients with a hierarchically densely connected U-net deep learning architecture.](https://doi.org/10.1088/1361-6560/ab039b){: .btn}
**Authors:** *Nguyen Dan, Jia Xun, Sher David, Lin Mu-Han, Iqbal Zohaib, Liu Hui, Jiang Steve B*

**Journal:** *Physics in medicine and biology*

*abstract:* The treatment planning process for patients with head and neck (H&N) cancer is regarded as one of the most complicated due to large target volume, multiple prescription dose levels, and many radiation-sensitive critical structures near the target. Treatment planning for this site requires a high level of human expertise and a tremendous amount of effort to produce personalized high quality plans, taking as long as a week, which deteriorates the chances of tumor control and patient survival. To solve this problem, we propose to investigate a deep learning-based dose prediction model, Hierarchically Densely Connected U-net, based on two highly popular network architectures: U-net and DenseNet. We find that this new architecture is able to accurately and efficiently predict the dose distribution, outperforming the other two models, the Standard U-net and DenseNet, in homogeneity, dose conformity, and dose coverage on the test data. Averaging across all organs at risk, our proposed model is capable of predicting the organ-at-risk max dose within 6.3% and mean dose within 5.1% of the prescription dose on the test data. The other models, the Standard U-net and DenseNet, performed worse, having an averaged organ-at-risk max dose prediction error of 8.2% and 9.3%, respectively, and averaged mean dose prediction error of 6.4% and 6.8%, respectively. In addition, our proposed model used 12 times less trainable parameters than the Standard U-net, and predicted the patient dose 4 times faster than DenseNet.

**Keywords:** **'Artificial Intelligence', 'Deep Learning', 'DenseNet', 'Dose Prediction', 'Head and Neck Cancer', 'Radiation Therapy', 'U-net'**

**Publication Date:** *2019-Jan-31*

#### [3. Measuring spatio-temporal accessibility to emergency medical services through big GPS data.](https://linkinghub.elsevier.com/retrieve/pii/S1353-8292(18)30331-9){: .btn}
**Authors:** *Xia Tianqi, Song Xuan, Zhang Haoran, Song Xiaoya, Kanasugi Hiroshi, Shibasaki Ryosuke*

**Journal:** *Health & place*

*abstract:* Medical accessibility is an important indicator for evaluating the effectiveness of public health services. However, the previous medical accessibility studies mainly focus on spatial accessibility without considering temporal variation in population distribution which is significant for evaluating access to emergency medical service (EMS). This paper proposes a model of spatio-temporal accessibility to EMS called ST-E2SFCA based on adapting the enhanced two-step floating catchment area (E2SFCA) method. We apply our method to the greater Tokyo area for a large volume of GPS dataset with millions of users and compare the accessibility difference over space and time. To evaluate our model, we also analyze the distinction of our model over different weight sets and compare the performance of ST-E2SFCA with the traditional E2SFCA. The result shows that our method can illustrate the temporal difference and is suitable for measuring the spatio-temporal accessibility to EMS, thus can guide the hospital location selection and urban planning.

**Keywords:** **'Big data', 'Emergency medical services', 'Enhanced Two Step Floating Catchment Area', 'Spatio-temporal analysis'**

**Publication Date:** *2019-Jan-28*

#### [4. Recurrent inference machines for reconstructing heterogeneous MRI data.](https://linkinghub.elsevier.com/retrieve/pii/S1361-8415(18)30607-8){: .btn}
**Authors:** *LÃ¸nning Kai, Putzky Patrick, Sonke Jan-Jakob, Reneman Liesbeth, Caan Matthan W A, Welling Max*

**Journal:** *Medical image analysis*

*abstract:* Deep learning allows for accelerated magnetic resonance image (MRI) reconstruction, thereby shortening measurement times. Rather than using sparsifying transforms, a prerequisite in Compressed Sensing (CS), suitable MRI prior distributions are learned from data. In clinical practice, both the underlying anatomy as well as image acquisition settings vary. For this reason, deep neural networks must be able to reapply what they learn across different measurement conditions. We propose to use Recurrent Inference Machines (RIM) as a framework for accelerated MRI reconstruction. RIMs solve inverse problems in an iterative and recurrent inference procedure by repeatedly reassessing the state of their reconstruction, and subsequently making incremental adjustments to it in accordance with the forward model of accelerated MRI. RIMs learn the inferential process of reconstructing a given signal, which, in combination with the use of internal states as part of their recurrent architecture, makes them less dependent on learning the features pertaining to the source of the signal itself. This gives RIMs a low tendency to overfit, and a high capacity to generalize to unseen types of data. We demonstrate this ability with respect to anatomy by reconstructing brain and knee scans, as well as other MRI acquisition settings, by reconstructing scans of different contrast and resolution, at different field strength, subjected to varying acceleration levels. We show that RIMs outperform CS not only with respect to quality metrics, but also according to a rating given by an experienced neuroradiologist in a double blinded experiment. Finally, we show with qualitative results that our model can be applied to prospectively under-sampled raw data, as acquired by pre-installed acquisition protocols.

**Keywords:** **'Deep learning', 'Inverse problems', 'MRI', 'Reconstruction'**

**Publication Date:** *2019-Jan-18*

#### [5. Validation of lesion simulations in clinical CT data for anonymized chest and abdominal CT databases.](https://doi.org/10.1002/mp.13412){: .btn}
**Authors:** *Robins Marthony, Solomon Justin, Koweek Lynne M Hurwitz, Christensen Jared, Samei Ehsan*

**Journal:** *Medical physics*

*abstract:* To make available to the medical imaging community a computed tomography (CT) image database composed of hybrid datasets (patient CT images with digitally inserted anthropomorphic lesions) where lesion ground truth is known a priori. It is envisioned that such a dataset could be a resource for the assessment of CT image quality, machine learning, and imaging technologies (e.g., computer aided detection (CAD) and segmentation algorithms).



**Publication Date:** *2019-Jan-31*

#### [6. Correlating exhaled aerosol images to small airway obstructive diseases: A study with dynamic mode decomposition and machine learning.](http://dx.plos.org/10.1371/journal.pone.0211413){: .btn}
**Authors:** *Xi Jinxiang, Zhao Weizhong*

**Journal:** *PloS one*

*abstract:* Exhaled aerosols from lungs have unique patterns, and their variation can be correlated to the underlying lung structure and associated abnormities. However, it is challenging to characterize such aerosol patterns and differentiate their difference because of their complexity. This challenge is even greater for small airway diseases, where the disturbance signals are weak.



**Publication Date:** *2019*

#### [7. An Accelerated Linearly Convergent Stochastic L-BFGS Algorithm.](https://dx.doi.org/10.1109/TNNLS.2019.2891088){: .btn}
**Authors:** *Chang Daqing, Sun Shiliang, Zhang Changshui*

**Journal:** *IEEE transactions on neural networks and learning systems*

*abstract:* The limited memory version of the Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) algorithm is the most popular quasi-Newton algorithm in machine learning and optimization. Recently, it was shown that the stochastic L-BFGS (sL-BFGS) algorithm with the variance-reduced stochastic gradient converges linearly. In this paper, we propose a new sL-BFGS algorithm by importing a proper momentum. We prove an accelerated linear convergence rate under mild conditions. The experimental results on different data sets also verify this acceleration advantage.



**Publication Date:** *2019-Jan-25*

#### [8. Object Detection With Deep Learning: A Review.](https://dx.doi.org/10.1109/TNNLS.2018.2876865){: .btn}
**Authors:** *Zhao Zhong-Qiu, Zheng Peng, Xu Shou-Tao, Wu Xindong*

**Journal:** *IEEE transactions on neural networks and learning systems*

*abstract:* Due to object detection's close relationship with video analysis and image understanding, it has attracted much research attention in recent years. Traditional object detection methods are built on handcrafted features and shallow trainable architectures. Their performance easily stagnates by constructing complex ensembles that combine multiple low-level image features with high-level context from object detectors and scene classifiers. With the rapid development in deep learning, more powerful tools, which are able to learn semantic, high-level, deeper features, are introduced to address the problems existing in traditional architectures. These models behave differently in network architecture, training strategy, and optimization function. In this paper, we provide a review of deep learning-based object detection frameworks. Our review begins with a brief introduction on the history of deep learning and its representative tool, namely, the convolutional neural network. Then, we focus on typical generic object detection architectures along with some modifications and useful tricks to improve detection performance further. As distinct specific detection tasks exhibit different characteristics, we also briefly survey several specific tasks, including salient object detection, face detection, and pedestrian detection. Experimental analyses are also provided to compare various methods and draw some meaningful conclusions. Finally, several promising directions and tasks are provided to serve as guidelines for future work in both object detection and relevant neural network-based learning systems.



**Publication Date:** *2019-Jan-28*

#### [9. Walking Imagery Evaluation in Brain Computer Interfaces via a New Deep Learning Framework.](https://dx.doi.org/10.1109/TNSRE.2019.2895064){: .btn}
**Authors:** *Lei Baiying, Liu Xiaolu, Liang Shuang, Hang Wenlong, Wang Qiong, Choi Kup-Sze, Qin Jing*

**Journal:** *IEEE transactions on neural systems and rehabilitation engineering : a publication of the IEEE Engineering in Medicine and Biology Society*

*abstract:* Brain-computer interfaces (BCIs) based on motor imagery (MI) have been widely used to support the rehabilitation of motor functions of upper limbs rather than lower limbs. This is probably because it is more difficult to detect brain activities of lower limb MI. In order to reliably detect the brain activities of lower limbs to restore or improve the walking ability of the disabled, we propose a new paradigm of walking imagery (WI) in a virtual environment (VE) in order to elicit reliable brain activities and achieve a significant training effect. First, we extract and fuse both spatial and time-frequency features as a multi-view feature (MVF) to represent the patterns in the brain activity. Second, we design a multi-view multi-level deep polynomial network (MMDPN) to explore the complementarity among the features so as to improve the detection of walking from an idle state. Our extensive experimental results show that the VE-based paradigm significantly performs better than the traditional text-based paradigm. In addition, the VE-based paradigm can effectively help users to modulate brain activities and improve the quality of electroencephalography signals. We also observe that the MMDPN outperforms other deep learning methods in terms of classification performance.



**Publication Date:** *2019-Jan-25*

#### [10. Mining within-trial oscillatory brain dynamics to address the variability of optimized spatial filters.](https://dx.doi.org/10.1109/TNSRE.2019.2894914){: .btn}
**Authors:** *Meinel Andreas, Kolkhorst Henrich, Tangermann Michael*

**Journal:** *IEEE transactions on neural systems and rehabilitation engineering : a publication of the IEEE Engineering in Medicine and Biology Society*

*abstract:* Data-driven spatial filtering algorithms optimize scores such as the contrast between two conditions to extract oscillatory brain signal components. Most machine learning approaches for filter estimation, however, disregard within-trial temporal dynamics and are extremely sensitive to changes in training data and involved hyperparameters. This leads to highly variable solutions and impedes the selection of a suitable candidate for, e.g., neurotechnological applications. Fostering component introspection, we propose to embrace this variability by condensing the functional signatures of a large set of oscillatory components into homogeneous clusters, each representing specific within-trial envelope dynamics. The proposed method is exemplified by and evaluated on a complex hand force task with a rich within-trial structure. Based on electroencephalography data of 18 healthy subjects, we found that the components' distinct temporal envelope dynamics are highly subject-specific. On average, we obtained seven clusters per subject, which were strictly confined regarding their underlying frequency bands. As the analysis method is not limited to a specific spatial filtering algorithm, it could be utilized for a wide range of neurotechnological applications, e.g., to select and monitor functionally relevant features for brain-computer interface protocols in stroke rehabilitation.



**Publication Date:** *2019-Jan-25*

