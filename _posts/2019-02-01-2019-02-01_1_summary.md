---
layout: post
title: 2019/02/01 46 Updates (1 - 10)
---
## 1. [Looking back 2018--focused on colorectal cancer].


*Journal: Zhonghua wei chang wai ke za zhi = Chinese journal of gastrointestinal surgery* *Publication Date: 2019-Jan-25*



*abstract:* Colorectal cancer is one of the most common malignant tumors, and its incidence and mortality are increasing year by year in China. In 2018, for the first time, the FIT-DNA test was written into the expert consensus as the recommended screening technology in China. As the core technology of colorectal cancer screening, colonoscopy for right colon cancer is further supported. With the application of artificial intelligence technology in colonoscopy, the efficiency and accuracy of screening will be greatly improved. New screening technologies represented by circulating tumor cell (CTC) and individualized screening programs based on molecular genetics are future directions. As the core of colorectal cancer treatment, surgery has become quite mature. Traditional laparoscopic surgery has become an optimal choice for colorectal cancer surgery. Open surgery, robotic surgery and single-incision laparoscopic surgery have not been found superior to multiport laparoscopic surgery. The focus of surgical research is to precisely select surgical methods, and to protect normal physiological function of patients. For example, in order to reduce complications and improve quality of life in patients undergoing rectal cancer surgery after neoadjuvant radiotherapy, the "Tianhe surgery" was invented by the authors' team. Chemotherapy as the basis of colorectal cancer treatment has shown good results in many aspects: The PRODIGE-7 trial has confirmed that systemic chemotherapy is more important for colorectal peritoneal metastasis after high quality cytoreductive surgery (CRS). While the addition of hyperthermic intraperitoneal chemotherapy (HIPEC) with oxaliplatin does not result in the better overall survival (OS), but increases the risk of postoperative complications. The FOWARC study has found that the FOLFOX regimen (oxaliplatin and fluorouracil) achieved a 3-year disease-free survival (DFS) rate similar to that of neoadjuvant chemoradiotherapy, challenging the clinical value of radiotherapy. Although several studies have confirmed that total neoadjuvant therapy (TNT) can improve pathological complete response (pCR) rate and DFS of patients with colorectal cancer, we do not recommend unretricted expansion of chemotherapy. How to combine the clinical characteristics and molecular biological markers to select high-risk groups for chemotherapy, and how to use personalized medicine according to the genetic characteristics of patients, are also hot spots of current research. Immunotherapy is a game-changer in all aspects of colorectal cancer. In order to adapt to the immune therapy, the efficacy evaluation standard of solid tumors (iRECIST) has been revised. Immune score could redefine tumor clinical staging system. Both the Checkmate-142 study for advanced tumors and the NCT03026140 study on neoadjuvant treatment for early tumors showed promising results. Although no significant progress has been seen in the EGFR-targeted therapy and VEGFR-targeted therapy, new targeted drugs such as Eltanexor (ETLA, kpt -8602) and cobimetinib (MEK inhibitor) have been found to be effective in clinical studies. According to the detection results of tumor-related signaling pathways in patients, cross-guidance selection of targeted drug therapy is also the direction of research. Although the IWWD research results give a big blow to the "watch and wait" strategy, with the exploration of TNT plan, more accurate imaging efficacy evaluation and the application of immunotherapy, the "watch and wait" strategy will also receive new attention. In recent years, we have seen the rapid development of artificial intelligence technology. Although it is still in the exploratory stage in the field of medicine, it will certainly reshape all aspects of colorectal cancer diagnosis and treatment in the future, leading the research direction.

## 2. Potential EEG biomarkers of sedation doses in intensive care patients unveiled by using a machine learning approach.
**Keywords:** **'EEG', 'ICU', 'brain networks', 'machine learning', 'sedation'**

*Journal: Journal of neural engineering* *Publication Date: 2019-Jan-31*

[https://doi.org/10.1088/1741-2552/ab039f](https://doi.org/10.1088/1741-2552/ab039f){: .btn}

*abstract:* Sedation of neurocritically ill patients is one of the most challenging situation in ICUs. Quantitative knowledge on the sedation effect on brain activity in that complex scenario could help to uncover new markers for sedation assessment. Hence, we aim to evaluate the existence of changes of diverse EEG-derived measures in deeply-sedated (RASS -Richmond Agitation-Sedation Scale- -4 and -5) neurocritically ill patients, and also whether sedation doses are related with those eventual changes. &#13; Approach: We performed an observational prospective cohort study in the Intensive Care Unit of the Hospital de la Princesa. Twenty-six adult patients suffered from Traumatic Brain Injury and Subarachnoid Hemorrhage were included in the present study. Long-term continuous electroencephalographic (EEG) recordings (2141h) and hourly annotated information were used to determine the relationship between intravenous sedation infusion doses and network and spectral EEG measures. To do that, two different strategies were followed: assessment of the statistical dependence between both variables using the Spearman correlation rank and by performing an automatic classification method based on a machine learning algorithm.&#13; Main results: More than 60% of patients presented a correlation greater than 0.5 in at least one of the calculated EEG measures with the sedation dose. The automatic classification method presented an accuracy of 84.3% in discriminating between different sedation doses. In both cases the nodes' degree was the most relevant measurement.&#13; Significance: The results presented here provide evidences of brain activity changes during deep sedation linked to sedation doses. Particularly, the capability of network EEG-derived measures in discriminating between different sedation doses could be the framework for the development of accurate methods for sedation levels assessment.

## 3. Three-dimensional radiotherapy dose prediction on head and neck cancer patients with a hierarchically densely connected U-net deep learning architecture.
**Keywords:** **'Artificial Intelligence', 'Deep Learning', 'DenseNet', 'Dose Prediction', 'Head and Neck Cancer', 'Radiation Therapy', 'U-net'**

*Journal: Physics in medicine and biology* *Publication Date: 2019-Jan-31*

[https://doi.org/10.1088/1361-6560/ab039b](https://doi.org/10.1088/1361-6560/ab039b){: .btn}

*abstract:* The treatment planning process for patients with head and neck (H&N) cancer is regarded as one of the most complicated due to large target volume, multiple prescription dose levels, and many radiation-sensitive critical structures near the target. Treatment planning for this site requires a high level of human expertise and a tremendous amount of effort to produce personalized high quality plans, taking as long as a week, which deteriorates the chances of tumor control and patient survival. To solve this problem, we propose to investigate a deep learning-based dose prediction model, Hierarchically Densely Connected U-net, based on two highly popular network architectures: U-net and DenseNet. We find that this new architecture is able to accurately and efficiently predict the dose distribution, outperforming the other two models, the Standard U-net and DenseNet, in homogeneity, dose conformity, and dose coverage on the test data. Averaging across all organs at risk, our proposed model is capable of predicting the organ-at-risk max dose within 6.3% and mean dose within 5.1% of the prescription dose on the test data. The other models, the Standard U-net and DenseNet, performed worse, having an averaged organ-at-risk max dose prediction error of 8.2% and 9.3%, respectively, and averaged mean dose prediction error of 6.4% and 6.8%, respectively. In addition, our proposed model used 12 times less trainable parameters than the Standard U-net, and predicted the patient dose 4 times faster than DenseNet.

## 4. Measuring spatio-temporal accessibility to emergency medical services through big GPS data.
**Keywords:** **'Big data', 'Emergency medical services', 'Enhanced Two Step Floating Catchment Area', 'Spatio-temporal analysis'**

*Journal: Health & place* *Publication Date: 2019-Jan-28*

[https://linkinghub.elsevier.com/retrieve/pii/S1353-8292(18)30331-9](https://linkinghub.elsevier.com/retrieve/pii/S1353-8292(18)30331-9){: .btn}

*abstract:* Medical accessibility is an important indicator for evaluating the effectiveness of public health services. However, the previous medical accessibility studies mainly focus on spatial accessibility without considering temporal variation in population distribution which is significant for evaluating access to emergency medical service (EMS). This paper proposes a model of spatio-temporal accessibility to EMS called ST-E2SFCA based on adapting the enhanced two-step floating catchment area (E2SFCA) method. We apply our method to the greater Tokyo area for a large volume of GPS dataset with millions of users and compare the accessibility difference over space and time. To evaluate our model, we also analyze the distinction of our model over different weight sets and compare the performance of ST-E2SFCA with the traditional E2SFCA. The result shows that our method can illustrate the temporal difference and is suitable for measuring the spatio-temporal accessibility to EMS, thus can guide the hospital location selection and urban planning.

## 5. Recurrent inference machines for reconstructing heterogeneous MRI data.
**Keywords:** **'Deep learning', 'Inverse problems', 'MRI', 'Reconstruction'**

*Journal: Medical image analysis* *Publication Date: 2019-Jan-18*

[https://linkinghub.elsevier.com/retrieve/pii/S1361-8415(18)30607-8](https://linkinghub.elsevier.com/retrieve/pii/S1361-8415(18)30607-8){: .btn}

*abstract:* Deep learning allows for accelerated magnetic resonance image (MRI) reconstruction, thereby shortening measurement times. Rather than using sparsifying transforms, a prerequisite in Compressed Sensing (CS), suitable MRI prior distributions are learned from data. In clinical practice, both the underlying anatomy as well as image acquisition settings vary. For this reason, deep neural networks must be able to reapply what they learn across different measurement conditions. We propose to use Recurrent Inference Machines (RIM) as a framework for accelerated MRI reconstruction. RIMs solve inverse problems in an iterative and recurrent inference procedure by repeatedly reassessing the state of their reconstruction, and subsequently making incremental adjustments to it in accordance with the forward model of accelerated MRI. RIMs learn the inferential process of reconstructing a given signal, which, in combination with the use of internal states as part of their recurrent architecture, makes them less dependent on learning the features pertaining to the source of the signal itself. This gives RIMs a low tendency to overfit, and a high capacity to generalize to unseen types of data. We demonstrate this ability with respect to anatomy by reconstructing brain and knee scans, as well as other MRI acquisition settings, by reconstructing scans of different contrast and resolution, at different field strength, subjected to varying acceleration levels. We show that RIMs outperform CS not only with respect to quality metrics, but also according to a rating given by an experienced neuroradiologist in a double blinded experiment. Finally, we show with qualitative results that our model can be applied to prospectively under-sampled raw data, as acquired by pre-installed acquisition protocols.

## 6. Validation of lesion simulations in clinical CT data for anonymized chest and abdominal CT databases.


*Journal: Medical physics* *Publication Date: 2019-Jan-31*

[https://doi.org/10.1002/mp.13412](https://doi.org/10.1002/mp.13412){: .btn}

*abstract:* To make available to the medical imaging community a computed tomography (CT) image database composed of hybrid datasets (patient CT images with digitally inserted anthropomorphic lesions) where lesion ground truth is known a priori. It is envisioned that such a dataset could be a resource for the assessment of CT image quality, machine learning, and imaging technologies (e.g., computer aided detection (CAD) and segmentation algorithms).

## 7. Correlating exhaled aerosol images to small airway obstructive diseases: A study with dynamic mode decomposition and machine learning.


*Journal: PloS one* *Publication Date: 2019*

[http://dx.plos.org/10.1371/journal.pone.0211413](http://dx.plos.org/10.1371/journal.pone.0211413){: .btn}

*abstract:* Exhaled aerosols from lungs have unique patterns, and their variation can be correlated to the underlying lung structure and associated abnormities. However, it is challenging to characterize such aerosol patterns and differentiate their difference because of their complexity. This challenge is even greater for small airway diseases, where the disturbance signals are weak.

## 8. An Accelerated Linearly Convergent Stochastic L-BFGS Algorithm.


*Journal: IEEE transactions on neural networks and learning systems* *Publication Date: 2019-Jan-25*

[https://dx.doi.org/10.1109/TNNLS.2019.2891088](https://dx.doi.org/10.1109/TNNLS.2019.2891088){: .btn}

*abstract:* The limited memory version of the Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) algorithm is the most popular quasi-Newton algorithm in machine learning and optimization. Recently, it was shown that the stochastic L-BFGS (sL-BFGS) algorithm with the variance-reduced stochastic gradient converges linearly. In this paper, we propose a new sL-BFGS algorithm by importing a proper momentum. We prove an accelerated linear convergence rate under mild conditions. The experimental results on different data sets also verify this acceleration advantage.

## 9. Object Detection With Deep Learning: A Review.


*Journal: IEEE transactions on neural networks and learning systems* *Publication Date: 2019-Jan-28*

[https://dx.doi.org/10.1109/TNNLS.2018.2876865](https://dx.doi.org/10.1109/TNNLS.2018.2876865){: .btn}

*abstract:* Due to object detection's close relationship with video analysis and image understanding, it has attracted much research attention in recent years. Traditional object detection methods are built on handcrafted features and shallow trainable architectures. Their performance easily stagnates by constructing complex ensembles that combine multiple low-level image features with high-level context from object detectors and scene classifiers. With the rapid development in deep learning, more powerful tools, which are able to learn semantic, high-level, deeper features, are introduced to address the problems existing in traditional architectures. These models behave differently in network architecture, training strategy, and optimization function. In this paper, we provide a review of deep learning-based object detection frameworks. Our review begins with a brief introduction on the history of deep learning and its representative tool, namely, the convolutional neural network. Then, we focus on typical generic object detection architectures along with some modifications and useful tricks to improve detection performance further. As distinct specific detection tasks exhibit different characteristics, we also briefly survey several specific tasks, including salient object detection, face detection, and pedestrian detection. Experimental analyses are also provided to compare various methods and draw some meaningful conclusions. Finally, several promising directions and tasks are provided to serve as guidelines for future work in both object detection and relevant neural network-based learning systems.

## 10. Walking Imagery Evaluation in Brain Computer Interfaces via a New Deep Learning Framework.


*Journal: IEEE transactions on neural systems and rehabilitation engineering : a publication of the IEEE Engineering in Medicine and Biology Society* *Publication Date: 2019-Jan-25*

[https://dx.doi.org/10.1109/TNSRE.2019.2895064](https://dx.doi.org/10.1109/TNSRE.2019.2895064){: .btn}

*abstract:* Brain-computer interfaces (BCIs) based on motor imagery (MI) have been widely used to support the rehabilitation of motor functions of upper limbs rather than lower limbs. This is probably because it is more difficult to detect brain activities of lower limb MI. In order to reliably detect the brain activities of lower limbs to restore or improve the walking ability of the disabled, we propose a new paradigm of walking imagery (WI) in a virtual environment (VE) in order to elicit reliable brain activities and achieve a significant training effect. First, we extract and fuse both spatial and time-frequency features as a multi-view feature (MVF) to represent the patterns in the brain activity. Second, we design a multi-view multi-level deep polynomial network (MMDPN) to explore the complementarity among the features so as to improve the detection of walking from an idle state. Our extensive experimental results show that the VE-based paradigm significantly performs better than the traditional text-based paradigm. In addition, the VE-based paradigm can effectively help users to modulate brain activities and improve the quality of electroencephalography signals. We also observe that the MMDPN outperforms other deep learning methods in terms of classification performance.

