---
layout: post
title: 2019/01/31 30 Updates (21 - 30)
---
#### [21. Towards reconstructing intelligible speech from the human auditory cortex.](http://dx.doi.org/10.1038/s41598-018-37359-z){: .btn}
**Authors:** *Akbari Hassan, Khalighinejad Bahar, Herrero Jose L, Mehta Ashesh D, Mesgarani Nima*

**Journal:** *Scientific reports*

*abstract:* Auditory stimulus reconstruction is a technique that finds the best approximation of the acoustic stimulus from the population of evoked neural activity. Reconstructing speech from the human auditory cortex creates the possibility of a speech neuroprosthetic to establish a direct communication with the brain and has been shown to be possible in both overt and covert conditions. However, the low quality of the reconstructed speech has severely limited the utility of this method for brain-computer interface (BCI) applications. To advance the state-of-the-art in speech neuroprosthesis, we combined the recent advances in deep learning with the latest innovations in speech synthesis technologies to reconstruct closed-set intelligible speech from the human auditory cortex. We investigated the dependence of reconstruction accuracy on linear and nonlinear (deep neural network) regression methods and the acoustic representation that is used as the target of reconstruction, including auditory spectrogram and speech synthesis parameters. In addition, we compared the reconstruction accuracy from low and high neural frequency ranges. Our results show that a deep neural network model that directly estimates the parameters of a speech synthesizer from all neural frequencies achieves the highest subjective and objective scores on a digit recognition task, improving the intelligibility by 65% over the baseline method which used linear regression to reconstruct the auditory spectrogram. These results demonstrate the efficacy of deep learning and speech synthesis algorithms for designing the next generation of speech BCI systems, which not only can restore communications for paralyzed patients but also have the potential to transform human-computer interaction technologies.



**Publication Date:** *2019-Jan-29*

#### [22. Epithelium segmentation using deep learning in H&E-stained prostate specimens with immunohistochemistry as reference standard.](http://dx.doi.org/10.1038/s41598-018-37257-4){: .btn}
**Authors:** *Bulten Wouter, Bándi Péter, Hoven Jeffrey, Loo Rob van de, Lotz Johannes, Weiss Nick, Laak Jeroen van der, Ginneken Bram van, Hulsbergen-van de Kaa Christina, Litjens Geert*

**Journal:** *Scientific reports*

*abstract:* Given the importance of gland morphology in grading prostate cancer (PCa), automatically differentiating between epithelium and other tissues is an important prerequisite for the development of automated methods for detecting PCa. We propose a new deep learning method to segment epithelial tissue in digitised hematoxylin and eosin (H&E) stained prostatectomy slides using immunohistochemistry (IHC) as reference standard. We used IHC to create a precise and objective ground truth compared to manual outlining on H&E slides, especially in areas with high-grade PCa. 102 tissue sections were stained with H&E and subsequently restained with P63 and CK8/18 IHC markers to highlight epithelial structures. Afterwards each pair was co-registered. First, we trained a U-Net to segment epithelial structures in IHC using a subset of the IHC slides that were preprocessed with color deconvolution. Second, this network was applied to the remaining slides to create the reference standard used to train a second U-Net on H&E. Our system accurately segmented both intact glands and individual tumour epithelial cells. The generalisation capacity of our system is shown using an independent external dataset from a different centre. We envision this segmentation as the first part of a fully automated prostate cancer grading pipeline.



**Publication Date:** *2019-Jan-29*

#### [23. Sequence Characteristics Distinguish Transcribed Enhancers from Promoters and Predict Their Breadth of Activity.](http://www.genetics.org/cgi/pmidlookup?view=long&pmid=30696717){: .btn}
**Authors:** *Colbran Laura L, Chen Ling, Capra John A*

**Journal:** *Genetics*

*abstract:* Enhancers and promoters both regulate gene expression by recruiting transcription factors; however, the degree to which enhancer vs. promoter activity is due to differences in their sequences or to genomic context is the subject of ongoing debate. We examined this question by analyzing the sequences of thousands of transcribed enhancers and promoters from hundreds of cellular contexts previously identified by Cap Analysis of Gene Expression (CAGE). Support vector machine (SVM) classifiers trained on counts of all possible 6-bp-long sequences (6-mers) were able to accurately distinguish promoters from enhancers and distinguish their breadth of activity across tissues. Classifiers trained to predict enhancer activity also performed well when applied to promoter prediction tasks, but promoter-trained classifiers performed poorly on enhancers. This suggests that the learned sequence patterns predictive of enhancer activity generalize to promoters, but not vice versa. Our classifiers also indicate that there are functionally relevant differences in enhancer and promoter GC content beyond the influence of CpG islands. Furthermore, sequences characteristic of broad promoter or broad enhancer activity matched different transcription factors (TFs), with predicted ETS and RFX binding sites indicative of promoters and AP-1 sites indicative of enhancers. Finally, we evaluated the ability of our models to distinguish enhancers and promoters defined by histone modifications. Separating these classes was substantially more difficult, and this difference may contribute to ongoing debates about the similarity of enhancers and promoters. In summary, our results suggest that high confidence transcribed enhancers and promoters can largely be distinguished based on biologically relevant sequence properties.

**Keywords:** **'enhancers', 'gene regulation', 'machine learning', 'promoters', 'sequence analysis'**

**Publication Date:** *2019-Jan-29*

#### [24. Integrative analysis identifies potential DNA methylation biomarkers for pan-cancer diagnosis and prognosis.](http://www.tandfonline.com/doi/full/10.1080/15592294.2019.1568178){: .btn}
**Authors:** *Ding Wubin, Chen Geng, Shi Tieliu*

**Journal:** *Epigenetics*

*abstract:* DNA methylation status is closely associated with diverse diseases, and is generally more stable than gene expression, thus abnormal DNA methylation could be important biomarkers for tumor diagnosis, treatment and prognosis. However, the signatures regarding DNA methylation changes for pan-cancer diagnosis and prognosis are less explored. Here we systematically analyzed the genome-wide DNA methylation patterns in diverse TCGA cancers with machine learning. We identified seven CpG sites that could effectively discriminate tumor samples from adjacent normal tissue samples for 12 main cancers of TCGA (1216 samples, AUC > 0.99). Those seven potential diagnostic biomarkers were further validated in the other 9 different TCGA cancers and 4 independent datasets (AUC > 0.92). Three out of the seven CpG sites were correlated with cell division, DNA replication and cell cycle. We also identified 12 CpG sites that can effectively distinguish 26 different cancers (7605 samples), and the result was repeatable in independent datasets as well as two disparate tumors with metastases (micro-average AUC > 0.89). Furthermore, a series of potential signatures that could significantly predict the prognosis of tumor patients for 7 different cancer were identified via survival analysis (p-value < 1e-4). Collectively, DNA methylation patterns vary greatly between tumor and adjacent normal tissues, as well as among different types of cancers. Our identified signatures may aid the decision of clinical diagnosis and prognosis for pan-cancer and the potential cancer-specific biomarkers could be used to predict the primary site of metastatic breast and prostate cancers.

**Keywords:** **'DNA methylation', 'cancer diagnosis', 'machine learning', 'pan-cancer', 'prognosis', 'survival analysis'**

**Publication Date:** *2019-Jan-29*

#### [25. Application of machine learning to predict obstructive sleep apnea syndrome severity.](http://journals.sagepub.com/doi/full/10.1177/1460458218824725?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub%3dpubmed){: .btn}
**Authors:** *Mencar Corrado, Gallo Crescenzio, Mantero Marco, Tarsia Paolo, Carpagnano Giovanna E, Foschino Barbaro Maria P, Lacedonia Donato*

**Journal:** *Health informatics journal*

*abstract:* Obstructive sleep apnea syndrome has become an important public health concern. Polysomnography is traditionally considered an established and effective diagnostic tool providing information on the severity of obstructive sleep apnea syndrome and the degree of sleep fragmentation. However, the numerous steps in the polysomnography test to diagnose obstructive sleep apnea syndrome are costly and time consuming. This study aimed to test the efficacy and clinical applicability of different machine learning methods based on demographic information and questionnaire data to predict obstructive sleep apnea syndrome severity.

**Keywords:** **'machine learning', 'obstructive sleep apnea syndrome'**

**Publication Date:** *2019-Jan-30*

#### [26. Large-Scale Assessment of Bioinformatics Tools for Lysine Succinylation Sites.](http://www.mdpi.com/resolver?pii=cells8020095){: .btn}
**Authors:** *Hasan Md Mehedi, Khatun Mst Shamima, Kurata Hiroyuki*

**Journal:** *Cells*

*abstract:* Lysine succinylation is a form of posttranslational modification of the proteins that play an essential functional role in every aspect of cell metabolism in both prokaryotes and eukaryotes. Aside from experimental identification of succinylation sites, there has been an intense effort geared towards the development of sequence-based prediction through machine learning, due to its promising and essential properties of being highly accurate, robust and cost-effective. In spite of these advantages, there are several problems that are in need of attention in the design and development of succinylation site predictors. Notwithstanding of many studies on the employment of machine learning approaches, few articles have examined this bioinformatics field in a systematic manner. Thus, we review the advancements regarding the current state-of-the-art prediction models, datasets, and online resources and illustrate the challenges and limitations to present a useful guideline for developing powerful succinylation site prediction tools.

**Keywords:** **'feature descriptor', 'lysine succinylation', 'machine learning', 'sequence analysis', 'tool development'**

**Publication Date:** *2019-Jan-28*

#### [27. Optimizing the Predictive Ability of Machine Learning Methods for Landslide Susceptibility Mapping Using SMOTE for Lishui City in Zhejiang Province, China.](http://www.mdpi.com/resolver?pii=ijerph16030368){: .btn}
**Authors:** *Wang Yumiao, Wu Xueling, Chen Zhangjian, Ren Fu, Feng Luwei, Du Qingyun*

**Journal:** *International journal of environmental research and public health*

*abstract:* The main goal of this study was to use the synthetic minority oversampling technique (SMOTE) to expand the quantity of landslide samples for machine learning methods (i.e., support vector machine (SVM), logistic regression (LR), artiﬁcial neural network (ANN), and random forest (RF)) to produce high-quality landslide susceptibility maps for Lishui City in Zhejiang Province, China. Landslide-related factors were extracted from topographic maps, geological maps, and satellite images. Twelve factors were selected as independent variables using correlation coefficient analysis and the neighborhood rough set (NRS) method. In total, 288 soil landslides were mapped using field surveys, historical records, and satellite images. The landslides were randomly divided into two datasets: 70% of all landslides were selected as the original training dataset and 30% were used for validation. Then, SMOTE was employed to generate datasets with sizes ranging from two to thirty times that of the training dataset to establish and compare the four machine learning methods for landslide susceptibility mapping. In addition, we used slope units to subdivide the terrain to determine the landslide susceptibility. Finally, the landslide susceptibility maps were validated using statistical indexes and the area under the curve (AUC). The results indicated that the performances of the four machine learning methods showed different levels of improvement as the sample sizes increased. The RF model exhibited a more substantial improvement (AUC improved by 24.12%) than did the ANN (18.94%), SVM (17.77%), and LR (3.00%) models. Furthermore, the ANN model achieved the highest predictive ability (AUC = 0.98), followed by the RF (AUC = 0.96), SVM (AUC = 0.94), and LR (AUC = 0.79) models. This approach significantly improves the performance of machine learning techniques for landslide susceptibility mapping, thereby providing a better tool for reducing the impacts of landslide disasters.

**Keywords:** **'Lishui City', 'SMOTE', 'landslide susceptibility', 'machine learning', 'neighborhood rough set theory', 'slope units'**

**Publication Date:** *2019-Jan-28*

#### [28. A Hierarchical Deep Fusion Framework for Egocentric Activity Recognition Using a Wearable Hybrid Sensor System.](http://www.mdpi.com/resolver?pii=s19030546){: .btn}
**Authors:** *Yu Haibin, Pan Guoxiong, Pan Mian, Li Chong, Jia Wenyan, Zhang Li, Sun Mingui*

**Journal:** *Sensors (Basel, Switzerland)*

*abstract:* Recently, egocentric activity recognition has attracted considerable attention in the pattern recognition and artificial intelligence communities because of its wide applicability in medical care, smart homes, and security monitoring. In this study, we developed and implemented a deep-learning-based hierarchical fusion framework for the recognition of egocentric activities of daily living (ADLs) in a wearable hybrid sensor system comprising motion sensors and cameras. Long short-term memory (LSTM) and a convolutional neural network are used to perform egocentric ADL recognition based on motion sensor data and photo streaming in different layers, respectively. The motion sensor data are used solely for activity classification according to motion state, while the photo stream is used for further specific activity recognition in the motion state groups. Thus, both motion sensor data and photo stream work in their most suitable classification mode to significantly reduce the negative influence of sensor differences on the fusion results. Experimental results show that the proposed method not only is more accurate than the existing direct fusion method (by up to 6%) but also avoids the time-consuming computation of optical flow in the existing method, which makes the proposed algorithm less complex and more suitable for practical application.

**Keywords:** **'deep learning', 'egocentric activity recognition', 'hierarchical fusion framework', 'wearable sensor system'**

**Publication Date:** *2019-Jan-28*

#### [29. Machine Learning and Integrative Analysis of Biomedical Big Data.](http://www.mdpi.com/resolver?pii=genes10020087){: .btn}
**Authors:** *Mirza Bilal, Wang Wei, Wang Jie, Choi Howard, Chung Neo Christopher, Ping Peipei*

**Journal:** *Genes*

*abstract:* Recent developments in high-throughput technologies have accelerated the accumulation of massive amounts of omics data from multiple sources: genome, epigenome, transcriptome, proteome, metabolome, etc. Traditionally, data from each source (e.g., genome) is analyzed in isolation using statistical and machine learning (ML) methods. Integrative analysis of multi-omics and clinical data is key to new biomedical discoveries and advancements in precision medicine. However, data integration poses new computational challenges as well as exacerbates the ones associated with single-omics studies. Specialized computational approaches are required to effectively and efficiently perform integrative analysis of biomedical data acquired from diverse modalities. In this review, we discuss state-of-the-art ML-based approaches for tackling five specific computational challenges associated with integrative analysis: curse of dimensionality, data heterogeneity, missing data, class imbalance and scalability issues.

**Keywords:** **'class imbalance', 'curse of dimensionality', 'data integration', 'heterogeneous data', 'machine learning', 'missing data', 'multi-omics', 'scalability'**

**Publication Date:** *2019-Jan-28*

#### [30. An Artificial Intelligence Application for Post-Earthquake Damage Mapping in Palu, Central Sulawesi, Indonesia.](http://www.mdpi.com/resolver?pii=s19030542){: .btn}
**Authors:** *Syifa Mutiara, Kadavi Prima Riza, Lee Chang-Wook*

**Journal:** *Sensors (Basel, Switzerland)*

*abstract:* A Mw 7.4 earthquake hit Donggala County, Central Sulawesi Province, Indonesia, on 28 September 2018, triggering a tsunami and liquefaction in Palu City and Donggala. Around 2101 fatalities ensued and 68,451 houses were damaged by the earthquake. In light of this devastating event, a post-earthquake map is required to establish the first step in the evacuation and mitigation plan. In this study, remote sensing imagery from the Landsat-8 and Sentinel-2 satellites was used. Pre- and post-earthquake satellite images were classified using artificial neural network (ANN) and support vector machine (SVM) classifiers and processed using a decorrelation method to generate the post-earthquake damage map. The affected areas were compared to the field data, the percentage conformity between the ANN and SVM results was analyzed, and four post-earthquake damage maps were generated. Based on the conformity analysis, the Landsat-8 imagery (85.83%) was superior to that of Sentinel-2 (63.88%). The resulting post-earthquake damage map can be used to assess the distribution of seismic damage following the Palu earthquake and may be used to mitigate damage in the event of future earthquakes.

**Keywords:** **'ANN', 'Palu earthquake', 'SVM', 'post-earthquake damage map'**

**Publication Date:** *2019-Jan-28*

