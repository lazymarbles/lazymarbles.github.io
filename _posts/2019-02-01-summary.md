---
layout: post
title: "2019/02/01 46 Updates"
---
## 1. Integrating shortest dependency path and sentence sequence into a deep learning framework for relation extraction in clinical text.
**'Relation extraction - deep learning', 'Shortest dependency path'**

*BMC medical informatics and decision making* *2019-Jan-31*
[link_](https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-019-0736-9){: .btn}
*abstract*Extracting relations between important clinical entities is critical but very challenging for natural language processing (NLP) in the medical domain. Researchers have applied deep learning-based approaches to clinical relation extraction; but most of them consider sentence sequence only, without modeling syntactic structures. The aim of this study was to utilize a deep neural network to capture the syntactic features and further improve the performances of relation extraction in clinical notes.

## 2. EEG Classification of Motor Imagery Using a Novel Deep Learning Framework.
**'EEG', 'convolutional neural network', 'deep learning', 'short-time Fourier transform', 'variational autoencoder'**

*Sensors (Basel, Switzerland)* *2019-Jan-29*
[link_](http://www.mdpi.com/resolver?pii=s19030551){: .btn}
*abstract*Successful applications of brain-computer interface (BCI) approaches to motor imagery (MI) are still limited. In this paper, we propose a classification framework for MI electroencephalogram (EEG) signals that combines a convolutional neural network (CNN) architecture with a variational autoencoder (VAE) for classification. The decoder of the VAE generates a Gaussian distribution, so it can be used to fit the Gaussian distribution of EEG signals. A new representation of input was developed by combining the time, frequency, and channel information from the EEG signal, and the CNN-VAE method was designed and optimized accordingly for this form of input. In this network, the classification of the extracted CNN features is performed via the deep network VAE. Our framework, with an average kappa value of 0.564, outperforms the best classification method in the literature for BCI Competition IV dataset 2b with a 3% improvement. Furthermore, using our own dataset, the CNN-VAE framework also yields the best performance for both three-electrode and five-electrode EEGs and achieves the best average kappa values 0.568 and 0.603, respectively. Our results show that the proposed CNN-VAE method raises performance to the current state of the art.

