---
layout: post
title: 2019/01/31 36 Updates (21 - 30)
---
## 20. Ontogeny of vocal rhythms in harbor seal pups: an exploratory study.
**Keywords:** **'bioacoustics', 'pinnipeds', 'rhythm', 'timing', 'vocal development'**

*Journal: Current zoology* *Publication Date: 2019-Feb*



*abstract:* Puppyhood is a very active social and vocal period in a harbor seal's life 

## 21. Rhythm and synchrony in animal movement and communication.


*Journal: Current zoology* *Publication Date: 2019-Feb*



*abstract:* 

## 22. FLOating-Window Projective Separator (FloWPS): A Data Trimming Tool for Support Vector Machines (SVM) to Improve Robustness of the Classifier.
**Keywords:** **'bioinformatics', 'gene expression', 'machine learning', 'oncology', 'personalized medicine', 'support vector machines'**

*Journal: Frontiers in genetics* *Publication Date: 2018*

[https://dx.doi.org/10.3389/fgene.2018.00717](https://dx.doi.org/10.3389/fgene.2018.00717){: .btn}

*abstract:* Here, we propose a heuristic technique of data trimming for SVM termed 

## 23. Guidance of Navigating Honeybees by Learned Elongated Ground Structures.
**Keywords:** **'compass alignment', 'ground structures', 'guiding landmarks', 'navigation', 'object recognition', 'sun compass'**

*Journal: Frontiers in behavioral neuroscience* *Publication Date: 2018*

[https://dx.doi.org/10.3389/fnbeh.2018.00322](https://dx.doi.org/10.3389/fnbeh.2018.00322){: .btn}

*abstract:* Elongated landscape features like forest edges, rivers, roads or boundaries of fields are particularly salient landmarks for navigating animals. Here, we ask how honeybees learn such structures and how they are used during their homing flights after being released at an unexpected location (catch-and-release paradigm). The experiments were performed in two landscapes that differed with respect to their overall structure: a rather feature-less landscape, and one rich in close and far distant landmarks. We tested three different forms of learning: learning during orientation flights, learning during training to a feeding site, and learning during homing flights after release at an unexpected site within the explored area. We found that bees use elongated ground structures, e.g., a field boundary separating two pastures close to the hive (Experiment 1), an irrigation channel (Experiment 2), a hedgerow along which the bees were trained (Experiment 3), a gravel road close to the hive and the feeder (Experiment 4), a path along an irrigation channel with its vegetation close to the feeder (Experiment 5) and a gravel road along which bees performed their homing flights (Experiment 6). Discrimination and generalization between the learned linear landmarks and similar ones in the test area depend on their object properties (irrigation channel, gravel road, hedgerow) and their compass orientation. We conclude that elongated ground structures are embedded into multiple landscape features indicating that memory of these linear structures is one component of bee navigation. Elongated structures interact and compete with other references. Object identification is an important part of this process. The objects are characterized not only by their appearance but also by their alignment in the compass. Their salience is highest if both components are close to what had been learned. High similarity in appearance can compensate for (partial) compass misalignment, and vice versa.

## 24. A Fast and Refined Cancer Regions Segmentation Framework in Whole-slide Breast Pathological Images.


*Journal: Scientific reports* *Publication Date: 2019-Jan-29*

[http://dx.doi.org/10.1038/s41598-018-37492-9](http://dx.doi.org/10.1038/s41598-018-37492-9){: .btn}

*abstract:* Supervised learning methods are commonly applied in medical image analysis. However, the success of these approaches is highly dependent on the availability of large manually detailed annotated dataset. Thus an automatic refined segmentation of whole-slide image (WSI) is significant to alleviate the annotation workload of pathologists. But most of the current ways can only output a rough prediction of lesion areas and consume much time in each slide. In this paper, we propose a fast and refined cancer regions segmentation framework v3_DCNN, which first preselects tumor regions using a classification model Inception-v3 and then employs a semantic segmentation model DCNN for refined segmentation. Our framework can generate a dense likelihood heatmap with the 1/8 side of original WSI in 11.5 minutes on the Camelyon16 dataset, which saves more than one hour for each WSI compared with the initial DCNN model. Experimental results show that our approach achieves a higher FROC score 83.5% with the champion's method of Camelyon16 challenge 80.7%. Based on v3 DCNN model, we further automatically produce heatmap of WSI and extract polygons of lesion regions for doctors, which is very helpful for their pathological diagnosis, detailed annotation and thus contributes to developing a more powerful deep learning model.

## 25. Towards reconstructing intelligible speech from the human auditory cortex.


*Journal: Scientific reports* *Publication Date: 2019-Jan-29*

[http://dx.doi.org/10.1038/s41598-018-37359-z](http://dx.doi.org/10.1038/s41598-018-37359-z){: .btn}

*abstract:* Auditory stimulus reconstruction is a technique that finds the best approximation of the acoustic stimulus from the population of evoked neural activity. Reconstructing speech from the human auditory cortex creates the possibility of a speech neuroprosthetic to establish a direct communication with the brain and has been shown to be possible in both overt and covert conditions. However, the low quality of the reconstructed speech has severely limited the utility of this method for brain-computer interface (BCI) applications. To advance the state-of-the-art in speech neuroprosthesis, we combined the recent advances in deep learning with the latest innovations in speech synthesis technologies to reconstruct closed-set intelligible speech from the human auditory cortex. We investigated the dependence of reconstruction accuracy on linear and nonlinear (deep neural network) regression methods and the acoustic representation that is used as the target of reconstruction, including auditory spectrogram and speech synthesis parameters. In addition, we compared the reconstruction accuracy from low and high neural frequency ranges. Our results show that a deep neural network model that directly estimates the parameters of a speech synthesizer from all neural frequencies achieves the highest subjective and objective scores on a digit recognition task, improving the intelligibility by 65% over the baseline method which used linear regression to reconstruct the auditory spectrogram. These results demonstrate the efficacy of deep learning and speech synthesis algorithms for designing the next generation of speech BCI systems, which not only can restore communications for paralyzed patients but also have the potential to transform human-computer interaction technologies.

## 26. Epithelium segmentation using deep learning in H&E-stained prostate specimens with immunohistochemistry as reference standard.


*Journal: Scientific reports* *Publication Date: 2019-Jan-29*

[http://dx.doi.org/10.1038/s41598-018-37257-4](http://dx.doi.org/10.1038/s41598-018-37257-4){: .btn}

*abstract:* Given the importance of gland morphology in grading prostate cancer (PCa), automatically differentiating between epithelium and other tissues is an important prerequisite for the development of automated methods for detecting PCa. We propose a new deep learning method to segment epithelial tissue in digitised hematoxylin and eosin (H&E) stained prostatectomy slides using immunohistochemistry (IHC) as reference standard. We used IHC to create a precise and objective ground truth compared to manual outlining on H&E slides, especially in areas with high-grade PCa. 102 tissue sections were stained with H&E and subsequently restained with P63 and CK8/18 IHC markers to highlight epithelial structures. Afterwards each pair was co-registered. First, we trained a U-Net to segment epithelial structures in IHC using a subset of the IHC slides that were preprocessed with color deconvolution. Second, this network was applied to the remaining slides to create the reference standard used to train a second U-Net on H&E. Our system accurately segmented both intact glands and individual tumour epithelial cells. The generalisation capacity of our system is shown using an independent external dataset from a different centre. We envision this segmentation as the first part of a fully automated prostate cancer grading pipeline.

## 27. Sequence Characteristics Distinguish Transcribed Enhancers from Promoters and Predict Their Breadth of Activity.
**Keywords:** **'enhancers', 'gene regulation', 'machine learning', 'promoters', 'sequence analysis'**

*Journal: Genetics* *Publication Date: 2019-Jan-29*

[http://www.genetics.org/cgi/pmidlookup?view=long&pmid=30696717](http://www.genetics.org/cgi/pmidlookup?view=long&pmid=30696717){: .btn}

*abstract:* Enhancers and promoters both regulate gene expression by recruiting transcription factors; however, the degree to which enhancer vs. promoter activity is due to differences in their sequences or to genomic context is the subject of ongoing debate. We examined this question by analyzing the sequences of thousands of transcribed enhancers and promoters from hundreds of cellular contexts previously identified by Cap Analysis of Gene Expression (CAGE). Support vector machine (SVM) classifiers trained on counts of all possible 6-bp-long sequences (6-mers) were able to accurately distinguish promoters from enhancers and distinguish their breadth of activity across tissues. Classifiers trained to predict enhancer activity also performed well when applied to promoter prediction tasks, but promoter-trained classifiers performed poorly on enhancers. This suggests that the learned sequence patterns predictive of enhancer activity generalize to promoters, but not vice versa. Our classifiers also indicate that there are functionally relevant differences in enhancer and promoter GC content beyond the influence of CpG islands. Furthermore, sequences characteristic of broad promoter or broad enhancer activity matched different transcription factors (TFs), with predicted ETS and RFX binding sites indicative of promoters and AP-1 sites indicative of enhancers. Finally, we evaluated the ability of our models to distinguish enhancers and promoters defined by histone modifications. Separating these classes was substantially more difficult, and this difference may contribute to ongoing debates about the similarity of enhancers and promoters. In summary, our results suggest that high confidence transcribed enhancers and promoters can largely be distinguished based on biologically relevant sequence properties.

## 28. Integrative analysis identifies potential DNA methylation biomarkers for pan-cancer diagnosis and prognosis.
**Keywords:** **'DNA methylation', 'cancer diagnosis', 'machine learning', 'pan-cancer', 'prognosis', 'survival analysis'**

*Journal: Epigenetics* *Publication Date: 2019-Jan-29*

[http://www.tandfonline.com/doi/full/10.1080/15592294.2019.1568178](http://www.tandfonline.com/doi/full/10.1080/15592294.2019.1568178){: .btn}

*abstract:* DNA methylation status is closely associated with diverse diseases, and is generally more stable than gene expression, thus abnormal DNA methylation could be important biomarkers for tumor diagnosis, treatment and prognosis. However, the signatures regarding DNA methylation changes for pan-cancer diagnosis and prognosis are less explored. Here we systematically analyzed the genome-wide DNA methylation patterns in diverse TCGA cancers with machine learning. We identified seven CpG sites that could effectively discriminate tumor samples from adjacent normal tissue samples for 12 main cancers of TCGA (1216 samples, AUC > 0.99). Those seven potential diagnostic biomarkers were further validated in the other 9 different TCGA cancers and 4 independent datasets (AUC > 0.92). Three out of the seven CpG sites were correlated with cell division, DNA replication and cell cycle. We also identified 12 CpG sites that can effectively distinguish 26 different cancers (7605 samples), and the result was repeatable in independent datasets as well as two disparate tumors with metastases (micro-average AUC > 0.89). Furthermore, a series of potential signatures that could significantly predict the prognosis of tumor patients for 7 different cancer were identified via survival analysis (p-value < 1e-4). Collectively, DNA methylation patterns vary greatly between tumor and adjacent normal tissues, as well as among different types of cancers. Our identified signatures may aid the decision of clinical diagnosis and prognosis for pan-cancer and the potential cancer-specific biomarkers could be used to predict the primary site of metastatic breast and prostate cancers.

## 29. Application of machine learning to predict obstructive sleep apnea syndrome severity.
**Keywords:** **'machine learning', 'obstructive sleep apnea syndrome'**

*Journal: Health informatics journal* *Publication Date: 2019-Jan-30*

[http://journals.sagepub.com/doi/full/10.1177/1460458218824725?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub%3dpubmed](http://journals.sagepub.com/doi/full/10.1177/1460458218824725?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub%3dpubmed){: .btn}

*abstract:* Obstructive sleep apnea syndrome has become an important public health concern. Polysomnography is traditionally considered an established and effective diagnostic tool providing information on the severity of obstructive sleep apnea syndrome and the degree of sleep fragmentation. However, the numerous steps in the polysomnography test to diagnose obstructive sleep apnea syndrome are costly and time consuming. This study aimed to test the efficacy and clinical applicability of different machine learning methods based on demographic information and questionnaire data to predict obstructive sleep apnea syndrome severity.

