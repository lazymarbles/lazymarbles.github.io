---
layout: post
title: 2019/02/09 29 Updates (11 - 20)
---
#### 11. U-Net-based Deep-Learning Bladder Segmentation in CT Urography.
No LinkOut links available for UID: 30734932

**Authors:** *Ma Xiangyuan, Hadjiiski Lubomir M, Wei Jun, Chan Heang-Ping, Cha Kenny H, Cohan Richard H, Caoili Elaine M, Samala Ravi, Zhou Chuan, Lu Yao*

**Journal:** *Medical physics*

*abstract:* To develop a U-Net based deep learning approach (U-DL) for bladder segmentation in computed tomography urography (CTU) as a part of a computer-assisted bladder cancer detection and treatment response assessment pipeline.

**Keywords:** **'Bladder', 'CT Urography', 'Computer-Aided Detection', 'Deep-Learning', 'Segmentation'**

**Publication Date:** *2019-Feb-08*

#### 12. Machine learning identifies "rsfMRI epilepsy networks" in temporal lobe epilepsy.
No LinkOut links available for UID: 30734849

**Authors:** *Bharath Rose Dawn, Panda Rajanikant, Raj Jeetu, Bhardwaj Sujas, Sinha Sanjib, Chaitanya Ganne, Raghavendra Kenchaiah, Mundlamuri Ravindranadh C, Arimappamagan Arivazhagan, Rao Malla Bhaskara, Rajeshwaran Jamuna, Thennarasu Kandavel, Majumdar Kaushik K, Satishchandra Parthasarthy, Gandhi Tapan K*

**Journal:** *European radiology*

*abstract:* Experimental models have provided compelling evidence for the existence of neural networks in temporal lobe epilepsy (TLE). To identify and validate the possible existence of resting-state "epilepsy networks," we used machine learning methods on resting-state functional magnetic resonance imaging (rsfMRI) data from 42 individuals with TLE.

**Keywords:** **'Magnetic resonance imaging', 'Seizures', 'Support vector machine', 'Temporal lobe epilepsy'**

**Publication Date:** *2019-Feb-08*

#### 13. Artificial intelligence in radiology: who's afraid of the big bad wolf?
No LinkOut links available for UID: 30734848

**Authors:** *Gallix Benoit, Chong Jaron*

**Journal:** *European radiology*

*abstract:* This Editorial comment refers to the article "Medical students' attitude towards artificial intelligence: a multicenter survey," Pinto Dos Santos D, et al Eur Radiol 2018. KEY POINTS: • Medical students are not well informed of the potential consequences of AI in radiology. • The fundamental principles of AI-as well as its application in medicine-must be taught in medical schools. • The radiologist specialty must actively reflect on how to validate, approve, and integrate AI algorithms into our clinical practices.

**Keywords:** **'Artificial intelligence (AI)', 'Diagnostic imaging', 'Education', 'Machine learning', 'Medical'**

**Publication Date:** *2019-Feb-08*

#### 14. fNIRS improves seizure detection in multimodal EEG-fNIRS recordings.
No LinkOut links available for UID: 30734544

**Authors:** *Sirpal Parikshat, Kassab Ali, Pouliot Philippe, Nguyen Dang Khoa, Lesage Frédéric*

**Journal:** *Journal of biomedical optics*

*abstract:* In the context of epilepsy monitoring, electroencephalography (EEG) remains the modality of choice. Functional near-infrared spectroscopy (fNIRS) is a relatively innovative modality that cannot only characterize hemodynamic profiles of seizures but also allow for long-term recordings. We employ deep learning methods to investigate the benefits of integrating fNIRS measures for seizure detection. We designed a deep recurrent neural network with long short-term memory units and subsequently validated it using the CHBMIT scalp EEG database-a compendium of 896 h of surface EEG seizure recordings. After validating our network using EEG, fNIRS, and multimodal data comprising a corpus of 89 seizures from 40 refractory epileptic patients was used as model input to evaluate the integration of fNIRS measures. Following heuristic hyperparameter optimization, multimodal EEG-fNIRS data provide superior performance metrics (sensitivity and specificity of 89.7% and 95.5%, respectively) in a seizure detection task, with low generalization errors and loss. False detection rates are generally low, with 11.8% and 5.6% for EEG and multimodal data, respectively. Employing multimodal neuroimaging, particularly EEG-fNIRS, in epileptic patients, can enhance seizure detection performance. Furthermore, the neural network model proposed and characterized herein offers a promising framework for future multimodal investigations in seizure detection and prediction.

**Keywords:** **'deep neural networks', 'electroencephalography-functional near-infrared spectroscopy', 'epilepsy', 'functional brain imaging', 'seizure detection'**

**Publication Date:** *2019-Feb*

#### 15. Machine learning: Great opportunities, but will it replace nurses?
No LinkOut links available for UID: 30734415

**Authors:** *Perry Lin*

**Journal:** *International journal of nursing practice*

*abstract:* 



**Publication Date:** *2019-Feb*

#### 16. Machine Learning for Automated Quality Assurance in Radiotherapy: A Proof of Principle using EPID Data Description.
No LinkOut links available for UID: 30734324

**Authors:** *El Naqa Issam, Irrer Jim, Ritter Tim A, DeMarco John, Al-Hallaq Hania, Booth Jeremy, Kim Grace, Alkhatib Ahmad, Popple Richard, Perez Mario, Farrey Karl, Moran Jean M*

**Journal:** *Medical physics*

*abstract:* Developing automated methods to identify task-driven quality assurance (QA) procedures is key towards increasing safety, efficacy, and efficiency. We investigate the use of machine learning (ML) methods for possible visualization, automation and targeting of QA, and assess its performance using multi-institutional data.

**Keywords:** **'\nSVM\n', 'Linacs', 'Machine learning', 'higher dimension visualization', 'quality assurance'**

**Publication Date:** *2019-Feb-07*

#### 17. Artificial intelligence systems for complex decision-making in acute care medicine: a review.
No LinkOut links available for UID: 30733829

**Authors:** *Lynn Lawrence A*

**Journal:** *Patient safety in surgery*

*abstract:* The integration of artificial intelligence (AI) into acute care brings a new source of intellectual thought to the bedside. This offers great potential for synergy between AI systems and the human intellect already delivering care. This much needed help should be embraced, if proven effective. However, there is a risk that the present role of physicians and nurses as the primary arbiters of acute care in hospitals may be overtaken by computers. While many argue that this transition is inevitable, the process of developing a formal plan to prevent the need to pass control of patient care to computers should not be further delayed. The first step in the interdiction process is to recognize; the limitations of existing hospital protocols, why we need AI in acute care, and finally how the focus of medical decision making will change with the integration of AI based analysis. The second step is to develop a strategy for changing the focus of medical education to empower physicians to maintain oversight of AI. Physicians, nurses, and experts in the field of safe hospital communication must control the transition to AI integrated care because there is significant risk during the transition period and much of this risk is subtle, unique to the hospital environment, and outside the expertise of AI designers. AI is needed in acute care because AI detects complex relational time-series patterns within datasets and this level of analysis transcends conventional threshold based analysis applied in hospital protocols in use today. For this reason medical education will have to change to provide healthcare workers with the ability to understand and over-read relational time pattern centered communications from AI. Medical education will need to place less emphasis on threshold decision making and a greater focus on detection, analysis, and the pathophysiologic basis of relational time patterns. This should be an early part of a medical student's education because this is what their hospital companion (the AI) will be doing. Effective communication between human and artificial intelligence requires a common pattern centered knowledge base. Experts in safety focused human to human communication in hospitals should lead during this transition process.



**Publication Date:** *2019*

#### 18. Modelling Animal Interactive Rhythms in Communication.
No LinkOut links available for UID: 30733626

**Authors:** *Ravignani Andrea, de Reus Koen*

**Journal:** *Evolutionary bioinformatics online*

*abstract:* Time is one crucial dimension conveying information in animal communication. Evolution has shaped animals' nervous systems to produce signals with temporal properties fitting their socio-ecological niches. Many quantitative models of mechanisms underlying rhythmic behaviour exist, spanning insects, crustaceans, birds, amphibians, and mammals. However, these computational and mathematical models are often presented in isolation. Here, we provide an overview of the main mathematical models employed in the study of animal rhythmic communication among conspecifics. After presenting basic definitions and mathematical formalisms, we discuss each individual model. These computational models are then compared using simulated data to uncover similarities and key differences in the underlying mechanisms found across species. Our review of the empirical literature is admittedly limited. We stress the need of using comparative computer simulations - both before and after animal experiments - to better understand animal timing in interaction. We hope this article will serve as a potential first step towards a common computational framework to describe temporal interactions in animals, including humans.

**Keywords:** **'agent-based modelling', 'bioacoustics', 'chorusing', 'evolutionary biology', 'evolutionary neuroscience', 'rhythm', 'turn-taking', 'zoology'**

**Publication Date:** *2019*

#### 19. Machine learning for MEG during speech tasks.
No LinkOut links available for UID: 30733596

**Authors:** *Kostas Demetres, Pang Elizabeth W, Rudzicz Frank*

**Journal:** *Scientific reports*

*abstract:* We consider whether a deep neural network trained with raw MEG data can be used to predict the age of children performing a verb-generation task, a monosyllable speech-elicitation task, and a multi-syllabic speech-elicitation task. Furthermore, we argue that the network makes predictions on the grounds of differences in speech development. Previous work has explored taking 'deep' neural networks (DNNs) designed for, or trained with, images to classify encephalographic recordings with some success, but this does little to acknowledge the structure of these data. Simple neural networks have been used extensively to classify data expressed as features, but require extensive feature engineering and pre-processing. We present novel DNNs trained using raw magnetoencephalography (MEG) and electroencephalography (EEG) recordings that mimic the feature-engineering pipeline. We highlight criteria the networks use, including relative weighting of channels and preferred spectro-temporal characteristics of re-weighted channels. Our data feature 92 subjects aged 4-18, recorded using a 151-channel MEG system. Our proposed model scores over 95% mean cross-validation accuracy distinguishing above and below 10 years of age in single trials of un-seen subjects, and can classify publicly available EEG with state-of-the-art accuracy.



**Publication Date:** *2019-Feb-07*

#### 20. Objective risk stratification of prostate cancer using machine learning and radiomics applied to multiparametric magnetic resonance images.
No LinkOut links available for UID: 30733585

**Authors:** *Varghese Bino, Chen Frank, Hwang Darryl, Palmer Suzanne L, De Castro Abreu Andre Luis, Ukimura Osamu, Aron Monish, Aron Manju, Gill Inderbir, Duddalwar Vinay, Pandey Gaurav*

**Journal:** *Scientific reports*

*abstract:* Multiparametric magnetic resonance imaging (mpMRI) has become increasingly important for the clinical assessment of prostate cancer (PCa), but its interpretation is generally variable due to its relatively subjective nature. Radiomics and classification methods have shown potential for improving the accuracy and objectivity of mpMRI-based PCa assessment. However, these studies are limited to a small number of classification methods, evaluation using the AUC score only, and a non-rigorous assessment of all possible combinations of radiomics and classification methods. This paper presents a systematic and rigorous framework comprised of classification, cross-validation and statistical analyses that was developed to identify the best performing classifier for PCa risk stratification based on mpMRI-derived radiomic features derived from a sizeable cohort. This classifier performed well in an independent validation set, including performing better than PI-RADS v2 in some aspects, indicating the value of objectively interpreting mpMRI images using radiomics and classification methods for PCa risk assessment.



**Publication Date:** *2019-Feb-07*

