---
layout: post
title: 2019/01/30 34 Updates (21 - 30)
---
## 20. Intelligent Computer Systems for Multiple Sclerosis Diagnosis: a Systematic Review of Reasoning Techniques and Methods.
**Keywords:** **'Artificial Intelligence', 'Clinical Decision Support Techniques', 'Computer-Assisted', 'Decision Support Systems', 'Diagnosis', 'Multiple Sclerosis'**

*Journal: Acta informatica medica : AIM : journal of the Society for Medical Informatics of Bosnia & Herzegovina : casopis Drustva za medicinsku informatiku BiH* *Publication Date: 2018-Dec*



*abstract:* Intelligent computer systems are used in diagnosing Multiple Sclerosis and help physicians in the accurate and timely diagnosis of the disease. This study focuses on a review of different reasoning techniques and methods used in intelligent systems to diagnose MS and analyze the application and efficiency of different reasoning methods in order to find the most efficient and applicable methods and techniques for MS diagnosis.

## 21. Data-Driven Subtyping of Parkinson's Disease Using Longitudinal Clinical Records: A Cohort Study.


*Journal: Scientific reports* *Publication Date: 2019-Jan-28*

[http://dx.doi.org/10.1038/s41598-018-37545-z](http://dx.doi.org/10.1038/s41598-018-37545-z){: .btn}

*abstract:* Parkinson's disease (PD) is associated with diverse clinical manifestations including motor and non-motor signs and symptoms, and emerging biomarkers. We aimed to reveal the heterogeneity of PD to define subtypes and their progression rates using an automated deep learning algorithm on the top of longitudinal clinical records. This study utilizes the data collected from the Parkinson's Progression Markers Initiative (PPMI), which is a longitudinal cohort study of patients with newly diagnosed Parkinson's disease. Clinical information including motor and non-motor assessments, biospecimen examinations, and neuroimaging results were used for identification of PD subtypes. A deep learning algorithm, Long-Short Term Memory (LSTM), was used to represent each patient as a multi-dimensional time series for subtype identification. Both visualization and statistical analysis were performed for analyzing the obtained PD subtypes. As a result, 466 patients with idiopathic PD were investigated and three subtypes were identified. Subtype I (Mild Baseline, Moderate Motor Progression) is comprised of 43.1% of the participants, with average age 58.79 ± 9.53 years, and was characterized by moderate functional decay in motor ability but stable cognitive ability. Subtype II (Moderate Baseline, Mild Progression) is comprised of 22.9% of the participants, with average age 61.93 ± 6.56 years, and was characterized by mild functional decay in both motor and non-motor symptoms. Subtype III (Severe Baseline, Rapid Progression) is comprised 33.9% of the patients, with average age 65.32 ± 8.86 years, and was characterized by rapid progression of both motor and non-motor symptoms. These subtypes suggest that when comprehensive clinical and biomarker data are incorporated into a deep learning algorithm, the disease progression rates do not necessarily associate with baseline severities, and the progression rate of non-motor symptoms is not necessarily correlated with the progression rate of motor symptoms.

## 22. [Establishment of a deep feature-based classification model for distinguishing benign and malignant breast tumors on full-filed digital mammography].
**Keywords:** **'breast tumors', 'computer-aided diagnosis', 'deep learning', 'full-filed digital mammography', 'radiomics'**

*Journal: Nan fang yi ke da xue xue bao = Journal of Southern Medical University* *Publication Date: 2019-Jan-30*



*abstract:* To develop a deep features-based model to classify benign and malignant breast lesions on full- filed digital mammography.

## 23. Time-lagged effects of weekly climatic and socio-economic factors on ANN municipal yard waste prediction models.
**Keywords:** **'Artificial neural networks', 'Climatic and socio-economic variables', 'Effects of lag', 'Municipal yard waste prediction model', 'Optimization of model structure'**

*Journal: Waste management (New York, N.Y.)* *Publication Date: 2019-Feb-01*

[https://linkinghub.elsevier.com/retrieve/pii/S0956-053X(18)30726-8](https://linkinghub.elsevier.com/retrieve/pii/S0956-053X(18)30726-8){: .btn}

*abstract:* Efficient and effective solid waste management requires sufficient ability to predict the operational capacity of a system correctly. Waste prediction models have been widely studied and these models are always being challenged to perform more accurately. Unlike waste prediction models for mixed wastes, variables for yard waste are time sensitive and the effects of lag must be explicitly considered. This study is the first to specifically look at lag times relating to variables that attempt to predict municipal yard waste generation using machine learning approaches. Weekly averaged climatic and socio-economic variables are screened through correlation analysis and the significant variables are then used to develop yard waste models. These models then utilize artificial neural networks (ANN) where the variables are time lagged for a different number of weeks. This helps to realize a reduction in the error of the predicted weekly yard waste generation. Optimal lag times for each model varied from 1 to 11 weeks. The best model used both the ambient air temperature and population variables, in an ANN model with 3 layers, 11 neurons in the hidden layer, and an optimal lag time of 1 week. A mean absolute percentage error of 18.72% was obtained during the testing stage. One model saw a 55.4% decrease in the mean squared error at training, showing the value of lag time on the accuracy of weekly yard waste prediction models.

## 24. Artificial Intelligence, Radiology, and the Way Forward.
**Keywords:** **'Artificial intelligence and ethics', 'Artificial intelligence and future', 'Artificial intelligence and way forward'**

*Journal: Canadian Association of Radiologists journal = Journal l'Association canadienne des radiologistes* *Publication Date: 2019-Feb*

[https://linkinghub.elsevier.com/retrieve/pii/S0846-5371(18)30147-5](https://linkinghub.elsevier.com/retrieve/pii/S0846-5371(18)30147-5){: .btn}

*abstract:* 

## 25. Machine Learning to Predict Delays in Adjuvant Radiation following Surgery for Head and Neck Cancer.
**Keywords:** **'NCDB', 'adjuvant therapy', 'delays in radiation therapy', 'machine learning', 'timing'**

*Journal: Otolaryngology--head and neck surgery : official journal of American Academy of Otolaryngology-Head and Neck Surgery* *Publication Date: 2019-Jan-29*

[http://journals.sagepub.com/doi/full/10.1177/0194599818823200?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub%3dpubmed](http://journals.sagepub.com/doi/full/10.1177/0194599818823200?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub%3dpubmed){: .btn}

*abstract:* To apply a novel methodology with machine learning (ML) to a large national cancer registry to help identify patients who are high risk for delayed adjuvant radiation.

## 26. RGB-D Object Recognition Using Multi-Modal Deep Neural Network and DS Evidence Theory.
**Keywords:** **'DS evidence theory', 'RGB-D object recognition', 'deep neural network', 'multi-modal learning'**

*Journal: Sensors (Basel, Switzerland)* *Publication Date: 2019-Jan-27*

[http://www.mdpi.com/resolver?pii=s19030529](http://www.mdpi.com/resolver?pii=s19030529){: .btn}

*abstract:* With the development of low-cost RGB-D (Red Green Blue-Depth) sensors, RGB-D object recognition has attracted more and more researchers' attention in recent years. The deep learning technique has become popular in the field of image analysis and has achieved competitive results. To make full use of the effective identification information in the RGB and depth images, we propose a multi-modal deep neural network and a DS (Dempster Shafer) evidence theory based RGB-D object recognition method. First, the RGB and depth images are preprocessed and two convolutional neural networks are trained, respectively. Next, we perform multi-modal feature learning using the proposed quadruplet samples based objective function to fine-tune the network parameters. Then, two probability classification results are obtained using two sigmoid SVMs (Support Vector Machines) with the learned RGB and depth features. Finally, the DS evidence theory based decision fusion method is used for integrating the two classification results. Compared with other RGB-D object recognition methods, our proposed method adopts two fusion strategies: Multi-modal feature learning and DS decision fusion. Both the discriminative information of each modality and the correlation information between the two modalities are exploited. Extensive experimental results have validated the effectiveness of the proposed method.

## 27. Learning Spatio Temporal Tactile Features with a ConvLSTM for the Direction Of Slip Detection.
**Keywords:** **'deep learning', 'direction of slip', 'spatio-temporal feature learning', 'tactile processing'**

*Journal: Sensors (Basel, Switzerland)* *Publication Date: 2019-Jan-27*

[http://www.mdpi.com/resolver?pii=s19030523](http://www.mdpi.com/resolver?pii=s19030523){: .btn}

*abstract:* Robotic manipulators have to constantly deal with the complex task of detecting whether a grasp is stable or, in contrast, whether the grasped object is slipping. Recognising the type of slippage-translational, rotational-and its direction is more challenging than detecting only stability, but is simultaneously of greater use as regards correcting the aforementioned grasping issues. In this work, we propose a learning methodology for detecting the direction of a slip (seven categories) using spatio-temporal tactile features learnt from one tactile sensor. Tactile readings are, therefore, pre-processed and fed to a ConvLSTM that learns to detect these directions with just 50 ms of data. We have extensively evaluated the performance of the system and have achieved relatively high results at the detection of the direction of slip on unseen objects with familiar properties (82.56% accuracy).

## 28. A Comparison of Machine Learning and Deep Learning Techniques for Activity Recognition using Mobile Devices.
**Keywords:** **'active aging', 'activity recognition', 'ambient-assisted living', 'deep learning', 'mHealth', 'safe environment'**

*Journal: Sensors (Basel, Switzerland)* *Publication Date: 2019-Jan-26*

[http://www.mdpi.com/resolver?pii=s19030521](http://www.mdpi.com/resolver?pii=s19030521){: .btn}

*abstract:* We have compared the performance of different machine learning techniques for human activity recognition. Experiments were made using a benchmark dataset where each subject wore a device in the pocket and another on the wrist. The dataset comprises thirteen activities, including physical activities, common postures, working activities and leisure activities. We apply a methodology known as the activity recognition chain, a sequence of steps involving preprocessing, segmentation, feature extraction and classification for traditional machine learning methods; we also tested convolutional deep learning networks that operate on raw data instead of using computed features. Results show that combination of two sensors does not necessarily result in an improved accuracy. We have determined that best results are obtained by the extremely randomized trees approach, operating on precomputed features and on data obtained from the wrist sensor. Deep learning architectures did not produce competitive results with the tested architecture.

## 29. Siamese Tracking from Single Point Initialization.
**Keywords:** **'Siamese network', 'contour detection', 'deep learning', 'object tracking'**

*Journal: Sensors (Basel, Switzerland)* *Publication Date: 2019-Jan-26*

[http://www.mdpi.com/resolver?pii=s19030514](http://www.mdpi.com/resolver?pii=s19030514){: .btn}

*abstract:* Recently, we have been concerned with locating and tracking vehicles in aerial videos. Vehicles in aerial videos usually have small sizes due to use of cameras from a remote distance. However, most of the current methods use a fixed bounding box region as the input of tracking. For the purpose of target locating and tracking in our system, detecting the contour of the target is utilized and can help with improving the accuracy of target tracking, because a shape-adaptive template segmented by object contour contains the most useful information and the least background for object tracking. In this paper, we propose a new start-up of tracking by clicking on the target, and implement the whole tracking process by modifying and combining a contour detection network and a fully convolutional Siamese tracking network. The experimental results show that our algorithm has significantly improved tracking accuracy compared to the state-of-the-art regarding vehicle images in both OTB100 and DARPA datasets. We propose utilizing our method in real time tracking and guidance systems.

